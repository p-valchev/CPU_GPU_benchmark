{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU vs GPU Performance Comparison\n",
    "\n",
    "\n",
    "#### Intel CPU vs. Intel HD Graphics\n",
    "\n",
    "Author: P. Valchev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "Training of neural networks can be accelerated by using the parallelism of calculations on GPUs. The Compute Unified Device Architecture (CUDA) is a parallel computing  platform and programming model used to produce custom code for the utilisation GPU which was developed by Nvidia and it is available on some Nvidia products. \n",
    "\n",
    "It should be pointed out that on a GPU increasing batch size will always try to fill up the entire GPU memory, which is not the case on the CPU. On the CPU an increase in batch size will increase the time pr. batch. Therefore a large batch size can be beneficial to be used on GPU. \n",
    "\n",
    "TensorFlow can, together with CUDA, make the use of the whole GPU architecture to further optimise computation time during model training.\n",
    "\n",
    "In [2] it is found that the differences in the performance of TensorFlow depends significantly on the processing unit and the more complex neural networks benefit from the GPUs parallelizing capabilities, which makes using GPU with TensorFlow well worth it in most cases. The authors agree also that the benefits of the GPU becomes insignificant when a simplistic neural network is trained with small instances of training data. At the end it is hard to draw any conclusion on the memory management of the GPU and CPU as the results indicate that the average memory allocation was affected mostly by the training data. All the comparison work was done with CUDA enabled GPU.\n",
    "\n",
    "In the literature there are examples of Tensorflow performance on CPU and CUDA supported GPU, but officially Tensorflow and Keras do not support any other GUP like Radeon or Intel Graphics. \n",
    "\n",
    "In this study, it will be looked into the performance of TensorFlow with respect to time. The question one can ask is: \n",
    "\n",
    "• Does the performance of TensorFlow / Keras generally benefit from using non-CUDA enabled GPU over the CPU when using TensorFlow/Keras, with regard to time efficiency?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install PlaidML\n",
    "\n",
    "\n",
    "PlaidML is an open source tensor compiler. Combined with Intel’s nGraph graph compiler, it gives popular deep learning frameworks performance portability across a wide range of CPU, GPU and other accelerator processor architectures. [1]\n",
    "\n",
    "![title](img/plaidML.png)\n",
    "\n",
    "## 1.1 Set-up virtual environment\n",
    "\n",
    "\n",
    "\n",
    "### Step 1. Preparation\n",
    "    Stop Jupyther Notebook if running.\n",
    "\n",
    "### Step 2. Create virtual environment\n",
    "    Create virtual environment in terminal with following command:\n",
    "\n",
    "        $ conda create -n plaid python=3.7\n",
    "\n",
    "![title](img/plaidML_create_env.png)\n",
    "    \n",
    "\n",
    "### Step 3. Activate virtual environment\n",
    "\n",
    "    To activate this environment, use:\n",
    "\n",
    "        $ conda activate plaid\n",
    "\n",
    "![title](img/plaidML_avitvate_env.png)\n",
    "\n",
    "    To deactivate an active environment, use\n",
    "        $ conda deactivate\n",
    "\n",
    "### Step 4. Validate virtual environment\n",
    "    verifiy if the environment is up and running:\n",
    "        $ echo $CONDA_DEFAULT_ENV\n",
    "    \n",
    "![title](img/plaidML_validate_env.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Install PlaidML\n",
    "\n",
    "### Step 5. Install PlaidML with Keras\n",
    "\n",
    "    $ pip install -U plaidml-keras opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6. Run installation script \n",
    "\n",
    "        $ plaidml-setup\n",
    "        \n",
    "            After executing the setup it is going to ask you if you want to enable experimental device, so confirm with \"yes\". Otherwise it will choose the one with metal in name, which is not going to work! PlaidML Keras uses OpenCL. \n",
    "            Select default devices by entering the coresponding number and confirm.\n",
    "            Last step is to save setting to this environment, so again confirm with \"yes\".\n",
    "    \n",
    "\n",
    "![title](img/plaidML_install.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Run Notebook\n",
    "\n",
    "    Start Jupyter Notebook in the newly created environment. Install numpy, pandas and ect in the environment if needed. \n",
    "    \n",
    "![title](img/Anaconda_Environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CPU - GPU Benchmark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Datasets\n",
    "\n",
    "## Fashion-MNIST Dataset\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. [3]\n",
    "\n",
    "Although the dataset is relatively simple, it can be used as the basis for learning and practicing how to develop, evaluate, and use deep convolutional neural networks for image classification from scratch. This includes how to develop a robust test harness for estimating the performance of the model, how to explore improvements to the model, and how to save the model and later load it to make predictions on new data.\n",
    "\n",
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. [4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Models\n",
    "\n",
    "\n",
    "\n",
    "## 2.2.1. Simple training model with small dataset\n",
    "\n",
    "In the Appendix 1 is a complete example that can be tried on system with installed PlaidML. It trains a very simple neural network with one hidden layer that sums input vectors.\n",
    "\n",
    "The code will be execuded on different computing devices (CPU and GPU). It will be surprising to find that training this model on CPU is faster, as the dataset is very small and the model very simple. \n",
    "\n",
    "Below is the comparison table:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2. Training model with Fashion-MNIST Dataset\n",
    "\n",
    "The training model is available in Apendix 2. The model is more complex than the previous model. As well the dataset hat 10 different classes. \n",
    "\n",
    "The comparison table shows the execution time on different devices:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3. Simple training model with Fashion-MNIST Dataset\n",
    "\n",
    "The code that need to be run is taken from [6]. This code is used for benchmarking VGG-19 in prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results\n",
    "\n",
    "Tested configurations\n",
    "\n",
    "![title](img/tested_hardware.png)\n",
    "\n",
    "### 3.1. Configuration 1\n",
    "Each model is executed three times - on the CPU (not PlaidML), GPU-OpenCL and GPU-Metal. During model execution CPU and GPU load were monitored, as well as all messages coming from PlaidML.\n",
    "\n",
    "### Tested hardware\n",
    "\n",
    "CPU: 1.6 GHz Dual-Core Intel Core i5 (I5-5250U)\n",
    "\n",
    "Graphics: Intel HD Graphics 6000\n",
    "\n",
    "\n",
    "### CUP load\n",
    "\n",
    "During model run on CPU:\n",
    "\n",
    "![title](img/CPU_Load_GPU_null.png)\n",
    "\n",
    "### GPU load\n",
    "\n",
    "During model run on GPU (openCL or metal):\n",
    "\n",
    "![title](img/GPU_during_executing.png)\n",
    "\n",
    "\n",
    "### PlaidML messages\n",
    "\n",
    "Import PlaidML Keras\n",
    "\n",
    "![title](img/Using_plaidml_keras.png)\n",
    "\n",
    "\n",
    "After model compilation the right GPU device is displayes:\n",
    "\n",
    "openCL\n",
    "![title](img/Using_OpenCL.png)\n",
    "\n",
    "Metal-GPU\n",
    "![title](img/Using_Metal.png)\n",
    "\n",
    "\n",
    "\n",
    "### 3.1.2 Result summary\n",
    "Results summary is in the table below:\n",
    "\n",
    "![title](img/Result_table.png)\n",
    "\n",
    "\n",
    "It is confirmed that on small datasets and simple models the CPU outperforms the GPU. \n",
    "Since Intel HD Graphic 6000 is not officially supported (tested by PlaidML) there are also problems during model run and convergence. For example, model training with Fashion-MNIST dataset, it is seen that GPU performs faster, but detailed look at the results shows much worse accuracy than CPU.\n",
    "\n",
    "Prediction with VGG19 is simply shows that openCL is not well optimized for this GPU. With another GPU could be different. \n",
    "\n",
    "### 3.1.3 Conclusion\n",
    "\n",
    "- On simple dataset and simple neural network model, the CPU has better performance.\n",
    "- Since GPU is not supported, the models can still run on Intel HD Graphics 6000 but the acieved accuracy is not satisfactory.\n",
    "- It can be confirmed that Intel HD Graphics 6000 is not optimezed for machine learning and even with PlaidML the results were not optimistic.\n",
    "- Genereally low end graphic adapters are not suitable for training machine learing models, which is expected.\n",
    "- Intel acquired the company which created PlaidML in 2018 but no big effort was done since then. In the near feature there are no signs that Intel will push PlaidML toward support of its own graphic adapters. \n",
    "- Without stronger Intel support is is very likely that PlaidML (which is open sourced) will be discontinued.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Configuration 2\n",
    "Each model is executed three times - on the CPU (not PlaidML) and GPU-OpenCL. During model execution CPU and GPU load were monitored, as well as all messages coming from PlaidML.\n",
    "\n",
    "### Tested hardware\n",
    "\n",
    "CPU: 1.9 GHz Intel i7 (I7-8665U)\n",
    "\n",
    "Graphics: AMD Radeon 550X (2Gb)\n",
    "\n",
    "\n",
    "### CUP load\n",
    "\n",
    "During model run on CPU:\n",
    "\n",
    "![title](img/2_CPU_load.png)\n",
    "\n",
    "### GPU load\n",
    "\n",
    "During model run on GPU (openCL or metal):\n",
    "\n",
    "![title](img/2_GPU_load.png)\n",
    "\n",
    "\n",
    "### PlaidML messages\n",
    "\n",
    "After model compilation the right GPU device is displayes:\n",
    "\n",
    "![title](img/2_opencl_info.png)\n",
    "\n",
    "\n",
    "\n",
    "### 3.1.2 Result summary\n",
    "Results summary is in the table below:\n",
    "\n",
    "![title](img/2_Results.png)\n",
    "\n",
    "\n",
    "It is confirmed that on small datasets and simple models the CPU outperforms the GPU. \n",
    "Fashion-MNIST dataset, it is seen that GPU performs faster. Model accuracy (trained on GPU and CPU) is similar.\n",
    "\n",
    "VGG19 is faster on GPU.\n",
    "\n",
    "### 3.1.3 Conclusion\n",
    "\n",
    "- On simple dataset and simple neural network model, the CPU has better performance.\n",
    "- The AMD Radeon 550X can be more than two times faster than the I7-8665U for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "\n",
    "Although there are some problems on running PlaidML on Intel HD Graphics 6000 it is still interesting to see this solution for deep learning. This experiment shows that it is in principle possilbe to train models in openCL but at the same time there is a lot to be done for further improve the system.\n",
    "\n",
    "On AMD Radeon 550X there is advantages to use GPU for model training, since it will reduce the training time. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography\n",
    "1. https://www.intel.com/content/www/us/en/artificial-intelligence/plaidml.html\n",
    "2. ERIC LIND, ÄVELIN PATNIGOSO, A performance comparison between CPU and GPU in TensorFlow, 2019.\n",
    "3. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "4. Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\n",
    "5. https://github.com/kennylimyx/plaidml/blob/main/plaidml_mnist_gpu_test.ipynb\n",
    "6. https://reposhub.com/cpp/machine-learning/plaidml-plaidml.html\n",
    "7. https://towardsdatascience.com/machine-learning-on-macos-with-an-amd-gpu-and-plaidml-55a46fe94bc0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1.\n",
    "## Simple training model with small dataset [7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import environ\n",
    "environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot as plt\n",
    "# Params\n",
    "num_samples = 100000 \n",
    "vect_len = 20\n",
    "max_int = 10\n",
    "min_int = 1\n",
    "\n",
    "# Generate dataset\n",
    "X = np.random.randint(min_int, max_int, (num_samples, vect_len))\n",
    "Y = np.sum(X, axis=1)\n",
    "\n",
    "# Get 80% of data for training\n",
    "split_idx = int(0.8 * len(Y))\n",
    "train_X = X[:split_idx, :]; test_X = X[split_idx:, :]\n",
    "train_Y = Y[:split_idx]; test_Y = Y[split_idx:]\n",
    "\n",
    "# Make model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(32, activation='relu', input_shape=(vect_len,)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile('adam', 'mse', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_Y, validation_data=(test_X, test_Y), \\\n",
    "                    epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2.\n",
    "## Training model with Fashion-MNIST Dataset [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Download fashion dataset from Keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Reshape and normalize the data\n",
    "x_train = x_train.astype('float32').reshape(60000,28,28,1) / 255\n",
    "x_test = x_test.astype('float32').reshape(10000,28,28,1) / 255\n",
    "\n",
    "# Build a CNN model\n",
    "# run this each time before you fit the model\n",
    "\n",
    "# if using plaidml, you should see \"INFO:plaidml:Opening device xxx\" after you run this chunk\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "%%time\n",
    "# Fit the model on training set\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=1028,\n",
    "          epochs=1)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
